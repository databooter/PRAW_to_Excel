{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a78127b7",
   "metadata": {},
   "source": [
    "The script does the following in this order:\n",
    "Connects to the Reddit API\n",
    "Loops through each subreddit in the subreddit list\n",
    "Creates an empty diction\"aries for the posts and comments in each subreddit\n",
    "Searches ALL of the “top” posts within each subreddit for posts that contain the input keyword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a87c1199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67cee097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_session(sub, query, path):\n",
    "    # Python Reddit API Wrapper (PRAW)\n",
    "    # We connect to reddit by calling praw.Reddit and storing it in the reddit variable\n",
    "    # client_id, client_secret, user_agent, username, password are passed as arguments\n",
    "    reddit = praw.Reddit(client_id='_14_Chars_Personal_Use_Script_',\n",
    "                         client_secret='_27_Chars_Secret_Key_',\n",
    "                         user_agent='_Your_User_Agent_')\n",
    "      \n",
    "        \n",
    "    # loop through each subreddit in the sub list with the reddit instance\n",
    "    # https://praw.readthedocs.io/en/latest/code_overview/reddit_instance.html?highlight=reddit    \n",
    "    for s in sub:\n",
    "        \n",
    "        # selecting the individual subreddit instance and putting it into the subreddit method\n",
    "        subreddit = reddit.subreddit(s) \n",
    "\n",
    "        # nested loop to search for the query keyword(s)\n",
    "        for item in query:\n",
    "            # creating a post dictionary to store post info\n",
    "            post_dict = {\n",
    "                \"title\": [],  # title of the post\n",
    "                \"score\": [],  # score of the post (upvotes/downvotes)\n",
    "                \"id\": [],  # id of the post\n",
    "                \"url\": [],  # url of the post\n",
    "                \"comms_num\": [],  # number of comments on the post\n",
    "                \"created\": [],  # UNIX timestamp\n",
    "                \"body\": []  # body of the post\n",
    "            }\n",
    "            # creating a comments dictionary to store comments info\n",
    "            comment_dict = {\n",
    "                \"comment_id\": [],  # id of the comment\n",
    "                \"comment_parent_id\": [],  # id of the parent post\n",
    "                \"comment_body\": [],  # body of the comment\n",
    "                \"comment_score\": [],  # score of the comment (upvotes/downvotes)\n",
    "                \"comment_link_id\": []  # id within the comment tree, within the parent id\n",
    "            }\n",
    "            \n",
    "            # POSTS ###############################################################################################\n",
    "\n",
    "            # nested, nested for loop to obtain each post element with the specified keyowrds in the query variable and append to post dictionary\n",
    "            # query is the specified input keyword variable from line 20\n",
    "            # sort is how Reddit sorts the posts. can be hot, new, rising, top, or controversial\n",
    "            # \"limit = None\" returns all posts\n",
    "            \n",
    "            for submission in subreddit.search(query,sort = \"top\",limit = None):\n",
    "                post_dict[\"title\"].append(submission.title)\n",
    "                post_dict[\"score\"].append(submission.score)\n",
    "                post_dict[\"id\"].append(submission.id)\n",
    "                post_dict[\"url\"].append(submission.url)\n",
    "                post_dict[\"comms_num\"].append(submission.num_comments)\n",
    "                post_dict[\"created\"].append(submission.created)\n",
    "                post_dict[\"body\"].append(submission.selftext)\n",
    "\n",
    "                \n",
    "                # COMMENTS ###############################################################################################\n",
    "\n",
    "                # for loop to obtain each comment element specified, from each post that was returned, and append to comment dictionary\n",
    "                # using replace_more with \"limit = None\" returns all comments from the comment forest\n",
    "                # https://praw.readthedocs.io/en/latest/tutorials/comments.html\n",
    "\n",
    "                submission.comments.replace_more(limit = None)\n",
    "                for comment in submission.comments.list():\n",
    "                    comments_dict[\"comment_id\"].append(comment.id)\n",
    "                    comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "                    comments_dict[\"comment_body\"].append(comment.body)\n",
    "                    comments_dict[\"comment_score\"].append(comment.score)\n",
    "                    comments_dict[\"comment_link_id\"].append(comment.link_id)\n",
    "                    \n",
    "            ###############################################################################################\n",
    "            \n",
    "            # putting each dictionary into a dataframe\n",
    "            comment_data = pd.DataFrame(comments_dict)\n",
    "            \n",
    "            # saving the comment_data to a csv\n",
    "            comment_data.to_csv(s+\"_subreddit_\"+ item +\"_comments.csv\")\n",
    "\n",
    "            # putting each post_dict dictionary into a dataframe\n",
    "            post_data = pd.DataFrame(post_dict)\n",
    "            \n",
    "            # function to create 'timestamp' column in datetime format from 'created' column (in UNIX format)\n",
    "            def get_date(created):\n",
    "                return dt.datetime.fromtimestamp(created)\n",
    "            \n",
    "            # applying the get_date function to the 'created' column and saving to '_timestamp' variable\n",
    "            _timestamp = post_data[\"created\"].apply(get_date)\n",
    "            \n",
    "            # assigning '_timestamp' variable to column in post_data df\n",
    "            post_data = post_data.assign(timestamp = _timestamp)\n",
    "            \n",
    "            # saving the post_data df to a csv file\n",
    "            post_data.to_csv(s+\"_subreddit_\"+ item + \"_posts.csv\")\n",
    "\n",
    "    # pulling all _post.csv files from path into posts\n",
    "    posts = glob.glob(path +'/*_posts.csv')\n",
    "\n",
    "    # establishing empty dataframe: posts_df\n",
    "    posts_df = pd.DataFrame()\n",
    "    \n",
    "    # establishing empty list: post_content\n",
    "    post_content = []\n",
    "    \n",
    "    # looping through posts, reading each csv, appending content to dataframe\n",
    "    for post in posts:\n",
    "        df = pd.read_csv(post, index_col=None)\n",
    "        post_content.append(df)\n",
    "    \n",
    "    # combining all the post dataframes into single dataframe\n",
    "    posts_df = pd.concat(post_content).reset_index(drop=True).drop(columns=\"Unnamed: 0\")\n",
    "    \n",
    "    # pulling all _comments.csv files from path into comments\n",
    "    comments = glob.glob(path +'/*_comments.csv')\n",
    "    \n",
    "    # establishing empty dataframe: comment_df\n",
    "    comment_df = pd.DataFrame()\n",
    "    \n",
    "    # establishing empty list comment_content\n",
    "    comment_content = []\n",
    "    \n",
    "    # looping through vomments, reading each csv, appending content to dataframe\n",
    "    for comment in comments:\n",
    "        df = pd.read_csv(filename, index_col=None)\n",
    "        comment_content.append(df)\n",
    "        \n",
    "    # combining all the comment dataframes into single dataframe\n",
    "    comment_df = pd.concat(comment_content).reset_index(drop=True).drop(columns=\"Unnamed: 0\")\n",
    "    \n",
    "    # dropping the first 3 characters from the ‘comment_link_id’ string in the comment_df \n",
    "    comment_df['id'] = comment_df['comment_link_id'].str[3:]\n",
    "    \n",
    "    # writing dataframes to two different worksheets in an excel workbook\n",
    "    with pd.ExcelWriter(f\"{query}_posts_and_comments.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "        posts_df.to_excel(writer, sheet_name='Posts')\n",
    "        comment_df.to_excel(writer, sheet_name='Comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17e5d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    " # make a list of subreddits you want to scrape the data from\n",
    "sub = [\"X\", \"Y\", \"Z\"] \n",
    "# make a list of the keywords to scrape for (1 is recommended)\n",
    "query = [\"A\"]\n",
    "path = (\"file_path_to_save_to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bb7e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run scrape sessions function\n",
    "scrape_session(sub, query, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
